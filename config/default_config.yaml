seed: 30 # original 42
dataset:
  img_size: 384
  mean: [0.69830354, 0.52184344, 0.41959074]
  std: [0.22212707, 0.23511315, 0.23065045]
  train_sample_size: 10000     # number of samples used per epoch
  val_split: 0.2              # based on train sample size
  classes: {0: 'benign', 1: 'malignant'}
pretrain:
  model_name: tf_efficientnet_b0
  checkpoint_path: "tf_efficientnet_b0_aa-827b6e33.pth"
train:
  epochs: 50
  train_batch_size: 32
  val_batch_size: 32
  n_accumulate: 1
  save_interval: 10
test:
  batch_size: 64
  test_sample_size: 50000
optimizer:
  learning_rate: 1e-4
  weight_decay: 1e-6
scheduler:
  name: 'CosineAnnealingLR'
  min_lr: 1e-6
  T_max: 500